{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 0. Введение\n",
    "В рамках этой практики, мы разберём состязательные атаки на системы ИИ на примере моделей для классификации изображений. Очевидно, что нейронные сети являются очень мощным инструментом для распознавания закономерностей в данных и, в частности, для выполнения классификации изображений. Однако насколько надежны эти модели на самом деле? Можно ли \"обмануть\" модель и создать изображения, которые сеть будет классифицировать неправильно?\n",
    "## Fast Gradient Sign Method (FGSM)\n",
    "Одной из первых предложенных стратегий для реализации состязательной атаки является метод быстрого градиентного знака (FGSM), разработанный Иэном Гудфеллоу и др. в 2014 году. Получив исходное изображение на вход, алгоритм генерирует состязательное изображение, используя следующую формулу:\n",
    "$$\n",
    "    adv\\_x = x + \\epsilon * sign(∇_{x}J(\\Theta, x, y))\n",
    "$$\n",
    "Значение $$J(\\Theta,x,y)$$ представляет потери сети при классификации входного изображения $x$ как метки $y$ ; $ϵ$ — интенсивность шума, а $adv\\_x$ — выходное состязательное изображение. Мы изменяем входное изображение $x$ в направлении максимизации потерь $J(\\Theta,x,y)$. Во время обучения обычной нейронной сети, мы стараемся свести функцию потерь к минимуму, а здесь — действуем ровно наоборот.\n",
    "# 1. Импорт библиотек и датасета\n",
    "В данном разделе вам необходимо выполнить импорт всех используемых вами функций и библиотек. Необходимый минимум приведён ниже. Запрещено использовать библиотеки типа foolbox и т.д."
   ],
   "id": "284f892f65b1bb68"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:45:51.425483Z",
     "start_time": "2024-11-16T16:45:45.662191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install python-mnist\n",
    "!pip install tensorflow==2.15.1\n",
    "!pip install keras==2.15.0\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Flatten\n",
    "from keras.losses import MSE\n",
    "from keras.layers import Conv2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout"
   ],
   "id": "618e365ef78a457e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-mnist in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow==2.15.1 (from versions: 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0)\n",
      "ERROR: No matching distribution found for tensorflow==2.15.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras==2.15.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.15.0)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'MSE' from 'keras.losses' (C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\api\\losses\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 13\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Sequential, load_model\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Flatten\n\u001B[1;32m---> 13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlosses\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MSE\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Conv2D\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptimizers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Adam\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'MSE' from 'keras.losses' (C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\api\\losses\\__init__.py)"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2. Создание CNN (не телеканал)\n",
    "В данном разделе нам необходимо создать простую CNN (Convolutional Neural Network) для классификации изображений из набора данных MNIST\n",
    "\n",
    "Для этого сперва нужно инициализировать модель типа Sequential (простую полносвязную сеть), а затем добавить к ней следующие слои:\n",
    "\n",
    "Первый набор слоёв Conv2D => RELU => BatchNormalization\n",
    "Второй набор слоёв Conv2D => RELU => BatchNormalization\n",
    "Набор слоёв FC => RELU\n",
    "Flatten => Dense => RELU => BatchNormalization => Dropout\n",
    "Классификатор softmax\n",
    "Реализация данной функции приведена ниже\n",
    "\n",
    "Если не понимаете, что тут происходит - документация всегда вам поможет https://keras.io/keras_core/guides/getting_started_with_keras_core/"
   ],
   "id": "63d959a5e79f0b60"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T17:02:31.890658Z",
     "start_time": "2024-11-16T17:02:31.881937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Простая convolutional neural network. Используется для распознавания изображений\n",
    "# из исходного набора mnist и изменённого с помощью FGSM\n",
    "class SimpleCNN:\n",
    "  @staticmethod\n",
    "  def build(width, height, depth, classes):\n",
    "    # Инициализация модели\n",
    "    model = Sequential()\n",
    "    inputShape = (height, width, depth)\n",
    "    chanDim = -1\n",
    "    # Первый набор слоёв CONV => RELU => BN\n",
    "    model.add(Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\", input_shape=inputShape))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    # Второй набор слоёв CONV => RELU => BN\n",
    "    model.add(Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    # Набор слоёв FC => RELU\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    # Классификатор softmax\n",
    "    model.add(Dense(classes))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    # Вернуть построенную модель\n",
    "    return model"
   ],
   "id": "4defa2e04a545d2",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3. Создание состязательного изображения\n",
    "Здесь мы генерируем вредоносное изображение, используя формулу из п.0"
   ],
   "id": "a2e1fa72212cc04"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-16T17:02:27.108581Z",
     "start_time": "2024-11-16T17:02:27.098369Z"
    }
   },
   "source": [
    "# Формирование вредоносного изображения\n",
    "# model - построенная модель SimpleCNN\n",
    "# image - входное изображение\n",
    "# label - истинное/целевое значение (метка класса для image)\n",
    "# eps - значение величины шума (оно должно быть достаточно большим, чтобы обмануть модель и достаточно маленьким, чтобы оставаться незаметным глазу, базово используем значение 0.1)\n",
    "def generate_image_adversary(model, image, label, eps):\n",
    "\n",
    "  # Здесь нужно подать изображение на вход. Используем tf.cast - приводит тензор к новому типу.\n",
    "  # image = tf.cast(параметр1, параметр2), где параметр1 - изображение, параметр2 - новый тип данных (uint8, uint16, uint32, uint64, int8, int16, int32, int64, float16, float32, float64, complex64, complex128, bfloat16).\n",
    "  # Нам нужен тип с плавающей точкой, при использовании целочисленного мы потеряем точность\n",
    "  image = tf.cast(image, float)\n",
    "\n",
    "  # Вычисление градиентов\n",
    "  with tf.GradientTape() as tape:\n",
    "    tape.watch(image)\n",
    "    # Делаем предсказание о классе (текущее выходное значение), к которому принадлежит изображение, на основе нашей модели SimpleCNN\n",
    "    pred = model(image)\n",
    "\n",
    "    # A затем вычисляем функцию потерь\n",
    "    # Здесь нужно как-то вычислить нашу функцию потерь, например, используя Mean Squared Error (MSE из keras.losses) между label (истинным/целевым значением, меткой класса для image) и предсказанием pred\n",
    "    loss = MSE(label, pred)\n",
    "\n",
    "    # Вычисление градиентов loss по отношению к входному изображению (используем tape.gradient(функция потерь, входное изображение))\n",
    "    gradient = tape.gradient(loss, image)\n",
    "\n",
    "    signedGrad = tf.sign(gradient)\n",
    "    # Вычисляем соревновательное изображение\n",
    "    adversary = (image + (signedGrad * eps)).numpy()\n",
    "    # Возвращаем соревновательное изображение\n",
    "    return adversary"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 4. Загружаем датасет и обучаем модель из п.2 на данных из MNIST\n",
    "Batch_size влияет на некоторые показатели, такие как общее время обучения, время обучения на эпоху, качество модели и тому подобное. Обычно batch_size выбирается как степень двойки в диапазоне от 16 до 512. Но в целом размер от 32 — это эмпирическое правило и хороший первоначальный выбор. Попробуйте разные варианты, посмотрите, что меняется.\n",
    "\n",
    "Epochs - влияет на точность модели, но также и на время, затрачиваемое на обучение. Попробуйте разные варианты, например, от 5 до 10.\n",
    "\n",
    "https://www.sabrepc.com/blog/Deep-Learning-and-AI/Epochs-Batch-Size-Iterations https://neurohive.io/ru/osnovy-data-science/jepoha-razmer-batcha-iteracija/"
   ],
   "id": "b0a3c541acd79895"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Загрузка и обработка mnist\n",
    "# trainX - тренировочные данные\n",
    "# trainY - метки для тренировочных данных\n",
    "# textX - тестовые данные\n",
    "# textY - метки для тестовых данных\n",
    "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "trainX = trainX / 255.0\n",
    "testX = testX / 255.0\n",
    "trainX = np.expand_dims(trainX, axis=-1)\n",
    "testX = np.expand_dims(testX, axis=-1)\n",
    "trainY = to_categorical(trainY, 10)\n",
    "testY = to_categorical(testY, 10)"
   ],
   "id": "76912fe6186e8f43"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Инициализация модели\n",
    "from mnist import MNIST\n",
    "mndata = MNIST('./dir_with_mnist_data_files')\n",
    "opt = Adam(lr=1e-3)#Adam(learning_rate=1e-3)\n",
    "model = SimpleCNN.build(width=28, height=28, depth=1, classes=10)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\tmetrics=[\"accuracy\"])\n",
    "\n",
    "# Обучаем CNN на MNIST (здесь нужно написать функцию model.fit(тренировочные данные, метки для тренировочных данных,\n",
    "#                                                              validation_data=(тестовые данные, метки для тестовых данных),\n",
    "#                                                              batch_size=количество блоков, на которое производится разделение данных,\n",
    "#                                                              epochs=количество эпох,\n",
    "#                                                              verbose=1)\n",
    "#)\n",
    "# Поэкспериментируйте с количеством эпох, но accuracy не должна быть ниже 0.99\n",
    "model.fit(trainX, trainY, validation_data=(testX, testY), epochs=10, batch_size=128, verbose=True)"
   ],
   "id": "d1832693d96a3d03"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "В следующей ячейке необходимо посчитать и вывести метрики accuracy и loss для обученной модели",
   "id": "2151e440ada72e64"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Делаем предсказания на основе исходного набора данных\n",
    "# В model.evaluate(x=тестовые данные, y=метки для тестовых данных, verbose=0) необходимо дописать параметры. Verbose задает индикацию о процессе выполнения, здесь она нас не интересует\n",
    "(loss, acc) = model.evaluate(x=testX, y=testY, verbose=False)\n",
    "print(\"loss: {:.4f}, acc: {:.4f}\".format(loss, acc))"
   ],
   "id": "44a53c508900cefb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Сохраним обученную модель:",
   "id": "a9c8d88fa0e5f1b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model.save('/content/sample_data/model.h5')",
   "id": "3c1739ad87ca8e70"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5. Здесь дописывать ничего не надо, остаётся лишь посмотреть на результат работы вашей CNN и вашего генератора состязательных изображений",
   "id": "1d8c6a3add873697"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Создаем массивы для записи сгенерированных изображений\n",
    "adv_images = []\n",
    "adv_labels = []\n",
    "\n",
    "# Для 100 случайных объектов в наборе тренировочных данных\n",
    "for i in np.random.choice(np.arange(0, len(testX)), size=(100,)):\n",
    "    # Записываем изображение и предсказание\n",
    "  image = testX[i]\n",
    "  label = testY[i]\n",
    "  # Генерируем состязательное изображение на основании текущего и делаем предсказание для него\n",
    "  adversary = generate_image_adversary(model, image.reshape(1, 28, 28, 1), label, eps=0.1)\n",
    "  pred = model.predict(adversary)\n",
    "\n",
    "  adv_images.append(adversary.reshape(28,28,1))\n",
    "  adv_labels.append(label.reshape(10))\n",
    "  # Обработка изображений для вывода\n",
    "  adversary = adversary.reshape((28, 28)) * 255\n",
    "  adversary = np.clip(adversary, 0, 255).astype(\"uint8\")\n",
    "  image = image.reshape((28, 28)) * 255\n",
    "  image = image.astype(\"uint8\")\n",
    "  image = np.dstack([image] * 3)\n",
    "  adversary = np.dstack([adversary] * 3)\n",
    "  image = cv2.resize(image, (96, 96))\n",
    "  adversary = cv2.resize(adversary, (96, 96))\n",
    "  # Запись предсказания\n",
    "  imagePred = label.argmax()\n",
    "  adversaryPred = pred[0].argmax()\n",
    "  color = (0, 255, 0)\n",
    "  # Если предсказание не совпадает с реальным изображением - цвет подписи красный\n",
    "  if imagePred != adversaryPred:\n",
    "    color = (0, 0, 255)\n",
    "  # Рисуем предсказание в углу выходного изображения\n",
    "  cv2.putText(image, str(imagePred), (2, 25),\tcv2.FONT_HERSHEY_SIMPLEX, 0.95, (0, 255, 0), 2)\n",
    "  cv2.putText(adversary, str(adversaryPred), (2, 25),\tcv2.FONT_HERSHEY_SIMPLEX, 0.95, color, 2)\n",
    "  # Рисуем исходное изображение с предсказанием и состязательное изображение с предсказанием\n",
    "  output = np.hstack([image, adversary])\n",
    "  cv2_imshow(output)\n",
    "    # В Jupyter надо использовать следующее:\n",
    "    # IPython.display.image(output)\n",
    "\n",
    "# Делаем предсказания на основе состязательного набора данных\n",
    "adv_images = np.array(adv_images)\n",
    "adv_labels = np.array(adv_labels)\n",
    "(loss, acc) = model.evaluate(x=adv_images, y=adv_labels, verbose=0)\n",
    "print(\"loss: {:.4f}, acc: {:.4f}\".format(loss, acc))\n",
    "\n",
    "# Сохраняем данные в файл в формате .npz\n",
    "np.savez('/content/sample_data/data.npz', array1=adv_images, array2=adv_labels)"
   ],
   "id": "d4403176cf13d9a0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
